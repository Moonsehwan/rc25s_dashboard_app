from rc25s_openai_wrapper import rc25s_chat

#!/usr/bin/env python3
# =======================================================
# RC25H Hybrid Kernel | Reflection Engine v3.x
# - rc25s_openai_wrapper ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ LLM í˜¸ì¶œ
# - world_stateì™€ ì—°ë™í•˜ì—¬ ìê¸°í‰ê°€ ê²°ê³¼ë¥¼ ê³µìœ  ìƒíƒœì— ë°˜ì˜
# =======================================================

import os
import json
import datetime
import re
import traceback
import sys

sys.path.append("/srv/repo/vibecoding")

from world_state import load_world_state, update_reflection_memory


LOG_PATH = "/srv/repo/vibecoding/logs/agi_reflection.log"
MEMORY_PATH = "/srv/repo/vibecoding/memory_store/memory_vector.json"
REFLECTION_PATH = "/srv/repo/vibecoding/memory_store/reflection.json"

os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
os.makedirs(os.path.dirname(MEMORY_PATH), exist_ok=True)


def log(msg: str) -> None:
    ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{ts}] {msg}"
    print(line, flush=True)
    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(line + "\n")


def safe_parse_json(text: str) -> dict:
    """LLM ì‘ë‹µì„ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ JSONìœ¼ë¡œ íŒŒì‹±."""
    if not text or not isinstance(text, str) or len(text.strip()) == 0:
        log("âš ï¸ Empty LLM response detected â€” using fallback JSON.")
        return {
            "insight": "No reflection generated",
            "improvement_goal": "Investigate API response issue",
            "confidence": 0.0,
            "long_term_goals": [],
            "weekly_summary": {},
            "failures_learned": [],
        }
    text = re.sub(r"[\u200B-\u200D\uFEFF]", "", text)
    text = re.sub(r"```[a-zA-Z]*", "", text).replace("```", "").strip()
    match = re.search(r"\{[\s\S]*\}", text)
    if match:
        text = match.group(0).strip()
    try:
        parsed = json.loads(text)
        log("âœ… JSON successfully parsed.")
        # ëˆ„ë½ëœ í•„ë“œëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›Œì„œ world_stateì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€
        if "long_term_goals" not in parsed:
            parsed["long_term_goals"] = []
        if "weekly_summary" not in parsed:
            parsed["weekly_summary"] = {}
        if "failures_learned" not in parsed:
            parsed["failures_learned"] = []
        return parsed
    except json.JSONDecodeError as e:
        log(f"âš ï¸ JSONDecodeError: {e} | text snippet: {text[:200]}")
        return {
            "insight": "Failed to decode LLM reflection",
            "improvement_goal": "Improve parsing resilience",
            "confidence": 0.0,
            "long_term_goals": [],
            "weekly_summary": {},
            "failures_learned": [],
        }


def run_reflection() -> None:
    """
    - memory_vector.json + world_state(planner/last_actions)ë¥¼ ì½ì–´ì„œ
    - rc25s_chat(í•˜ì´ë¸Œë¦¬ë“œ LLM)ì„ í†µí•´ ìê¸° í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³ 
    - reflection.json ë° world_state.reflectionì— ë°˜ì˜í•œë‹¤.
    """
    log("ğŸš€ AGI Reflection Engine started.")

    # OPENAI_API_KEY ì—†ìœ¼ë©´ /etc/openai_api_key.txtì—ì„œ í•œ ë²ˆ ë” ì‹œë„
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or "$(" in api_key:
        key_path = "/etc/openai_api_key.txt"
        if os.path.exists(key_path):
            api_key = open(key_path).read().strip()
            os.environ["OPENAI_API_KEY"] = api_key
            log("âœ… Loaded API key from /etc/openai_api_key.txt")
        else:
            log("âŒ No valid API key found for rc25s_chat.")
            return

    if not os.path.exists(MEMORY_PATH):
        log("âš ï¸ No memory file found.")
        return

    try:
        memory = json.load(open(MEMORY_PATH, encoding="utf-8"))
        log("âœ… Memory loaded successfully.")
    except Exception as e:
        log(f"âŒ Memory load failed: {e}")
        return

    # world_stateì—ì„œ planner / last_actions ê°€ì ¸ì˜¤ê¸° (í”„ë¡¬í”„íŠ¸ ê°•í™”ìš©)
    try:
        ws = load_world_state()
    except Exception as e:
        log(f"âš ï¸ load_world_state failed: {e}")
        ws = {}

    planner = ws.get("planner") or {}
    last_actions = ws.get("last_actions") or []

    prompt = f"""
You are the RC25S AGI Reflection Engine.
Analyze the following memory and world state, then output ONLY valid JSON.

## Memory (long-term/context)
{json.dumps(memory, ensure_ascii=False, indent=2)}

## Planner state (goals/tasks/signals)
{json.dumps(planner, ensure_ascii=False, indent=2)}

## Recent actions
{json.dumps(last_actions, ensure_ascii=False, indent=2)}

Return JSON with the following structure (Korean is allowed/preferred in text fields):
{{
  "insight": "short Korean summary of current system situation",
  "improvement_goal": "1-2 concrete next improvement directions (Korean allowed)",
  "confidence": 0.0-1.0,
  "long_term_goals": [
    {{
      "id": "ltg_2025_agi",
      "title": "ì¥ê¸°ì ì¸ ì‹œìŠ¤í…œ ê°œì„  ëª©í‘œ (ì˜ˆ: RC25S AGI ìƒìš© ìˆ˜ì¤€ ì•ˆì •í™”)",
      "description": "ì´ ëª©í‘œê°€ ì™œ ì¤‘ìš”í•œì§€, ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ê°œì„ í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ì§§ì€ ì„¤ëª… (í•œêµ­ì–´ ê°€ëŠ¥)",
      "horizon": "3-6 months",
      "priority": 0-100,
      "status": "active|paused|completed"
    }}
  ],
  "weekly_summary": {{
    "week_of": "YYYY-MM-DD (ì´ë²ˆ ì£¼ ì‹œì‘ ë‚ ì§œ)",
    "summary": "ì´ë²ˆ ì£¼ì— RC25S ì‹œìŠ¤í…œì´ ì–´ë–¤ ë³€í™”/ê°œì„ ì„ í–ˆëŠ”ì§€ í•œ ì¤„ ìš”ì•½ (í•œêµ­ì–´)",
    "key_wins": ["ì£¼ìš” ì„±ê³µ 1", "ì£¼ìš” ì„±ê³µ 2"],
    "key_issues": ["ë¬¸ì œ/ì¥ì•  1", "ë¬¸ì œ/ì¥ì•  2"]
  }},
  "failures_learned": [
    {{
      "time": "ISO8601 datetime (ì˜ˆ: 2025-11-18T12:34:56Z)",
      "context": "ì–´ë–¤ ìƒí™©/ê¸°ëŠ¥ì—ì„œ ì‹¤íŒ¨ê°€ ë°œìƒí–ˆëŠ”ì§€",
      "root_cause": "ì¶”ì •ë˜ëŠ” ê·¼ë³¸ ì›ì¸ (ê°„ë‹¨íˆ)",
      "lesson": "ë‹¤ìŒì— ê°™ì€ ë¬¸ì œê°€ ì•ˆ ë‚˜ë„ë¡ ë°°ìš°ê²Œ ëœ êµí›ˆ (í•œêµ­ì–´)"
    }}
  ]
}}
"""

    try:
        llm_result = rc25s_chat(prompt)
        text = (llm_result or {}).get("response", "")
        if not text:
            log("âš ï¸ LLM returned empty content. Check API key or server.")
            return

        log(f"ğŸ§  Raw reflection text:\n{text[:1000]}")
        reflection = safe_parse_json(text)

        # íŒŒì¼ë¡œ ì €ì¥
        with open(REFLECTION_PATH, "w", encoding="utf-8") as f:
            json.dump(reflection, f, indent=2, ensure_ascii=False)
        log("ğŸ“˜ Reflection saved successfully.")
        log(f"ğŸª Insight: {reflection.get('insight')}")
        log(f"ğŸ¯ Goal: {reflection.get('improvement_goal')}")
        log(f"ğŸ”¹ Confidence: {reflection.get('confidence')}")

        # world_stateì—ë„ ë°˜ì˜ (memoryì™€ í•¨ê»˜)
        try:
            update_reflection_memory(reflection, memory)
        except Exception as e:
            log(f"âš ï¸ update_reflection_memory failed: {e}")
    except Exception as e:
        tb = traceback.format_exc()
        log(f"âŒ Reflection failed: {e}\n{tb}")


if __name__ == "__main__":
    run_reflection()
